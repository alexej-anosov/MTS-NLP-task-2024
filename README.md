# MTS. NLP task. 2024

## Содержание
- [Введение](#введение)
- [Ход работы](#ход-работы)
  - [Данные](#данные)
  - [Описание агента](#описание-агента)
  - [Оценивание агента](#оценивание-агента)
  - [Дообучение агента](#дообучение-агента)
- [Результаты](#результаты)
- [Дальнейшие шаги](#дальнейшие-шаги)
- [Воспроизводимость](#воспроизводимость)
- [Использование сервиса](#использование-сервиса)
- [Стэк](#стэк)
- [Структура проекта](#структура-проекта)
- [Лицензия](#лицензия)

## Введение
Целью данного проекта является создание агента на основе небольшой (до 7B params) open-source языковой модели , обратившись к которому пользователь может заказать себе билеты на самолёт. В качестве модели была выбрана Mistral7B-Instruct-v0.3.

На данный проект использует синтетические данные и mock функции, однако в будущем возможно подключение настоящих API.

## Ход работы
### Данные
Использованы сгенерированные самостоятельно данные о перелётах за Июль 2024 года между 85 городами. Перелеты между двумя городами отличаются числом пересадок, временем отправки и прибытия, временем в воздухе, классом билета и ценой. Это позволяет иммитировать различные сценарии общения пользователя с моделью. Подробнее о генерации данных можно прочитать в [`report`](.report.pdf).

### Описание агента
В качестве инструмента для создания агента использовался LangChain. 

Работа агента организована аналогично фреймворку ReAct. На каждом шаге от модели ожидается json вида:
```json
{"thought": "<model's thoughts>",
 "action": "<tool name or Final Answer to give a final answer>",
 "action_input": "<tool parameters or the final output"}
```

Агент имеет 6 инструментов:
| Инструмент  | Функция |
| ------------- | ------------- |
| get current time  |  Позволяет получить текущее время и день недели. Для тестовых целей всегда выдает 2024-07-10 17:00, Wednesday. Инструмент позволяет отвечать на запросы типа 'Купи билет на следующую пятницу', а также проверять, что запрошенная дата не в прошлом.  |
| get availible cities   | Позволяет получить список доступных в данных городов. Также помогает с исправлением опечаток или альтернативных написаний городов. |
| ask user for info  | Позволяет передать пользователю вопрос. Пользователь отвечает с помощью ввода в консоль.  |
| ask user to choose  | Позволяет согласовать билет с пользователем. Действует аналогично  ask user for info, только еще принимает список json-ов с данными рейсов.  |
| buy ticket  | Позволяет купить билет. На вход принимает json с информацией о рейсе.  |


### Оценивание агента
В качестве главной метрики качества была использована человеческая оценка. 

Были сгенерированы 20 запросов (некоторые из них содержат всю необходимую информацию для однозначного выбора билета, другие требует от модели задать пользователю ряд вопросов (ответы на возможные вопросы также содержатся в датасете в отдельном поле)). Для каждого запроса был найден вручную нужный правильный билет.

Для оценивания качества модели эксперт проходится по данным запросам, отвечая на вопросы модели и наблюдая за ее шагами. За правильный итоговый ответ модель получает баллы, однако за лишние действия (вопросы к пользователю или использование других инструментов) модель штрафуется. Подробнее о генерации данных и формуле оценивания можно прочитать в [`report`](.report.pdf).

### Дообучение
В процессе создания агента, по мере добавления новых инструментов, способность агента ими управляться быстро падала. В связи с этим появилась необходимость в дообучении модели.
Данные для дообучения были собраны с помощью модели Gpt-4o. Всего было собрано 325 примеров (45 полных диалогов, 3 из них выделено в качестве тестовой выборки при обучении).
Исходная модель была дообучена на данных примерах с помощью LoRA. Результаты можно посмотреть [здесь]. Более подробно об экспериментах можно прочитать в [`report`](.report.pdf).

## Результаты


## Дальнейшие шаги
Автоматизировать проведение экспериментов:
* Автоматизировать оценивание работы модели с помощью API более крупной модели. Так как критерии оценки довольно четко сформулированы, такое решение должно работать хорошо. Для более стабильной оценки можно усреднять по нескольким прогонам оцениваемой и оценивающей моделей.
* Автоматизировать сбор тренировочного датасете с помощью API более крупной модели. Возможно, даже без отбора неудачных сэмплов можно получить существенное улучшение качества.

Это даст возможность прооводить много экспериментов, например со структурой промпта, фреймворком деятельности агента (Reflection, ..), различными моделями в качестве основы.

## Воспроизводимость
* Python: 3.10.14
* GPU: Tesla V100-SXM2-32GB, Driver Version: 555.42.06, CUDA Version: 12.5
* Список зависимостей расположен в файле `requirements.txt`. 
* Для настройки среды необходимо сделать следующиее находясь в корне проекта:
    ```
    pip install -r requirements.txt
    ```
    
## Использование сервиса
Использование сервиса возможно в 3 режимах: 
1) Inference. Пользователь вводит запрос вручную. Общение с агентом происходит через командную строку. Для запуска модели необходимо выполнить команду:
    ```
    python main.py --config_path <config_path>
    ```
    Доступные конфиги находятся в папке ./configs/inference
    
2) Evaluation. Агент сам итерируется по тестовому датасету. Общение с агентом происходит через командную строку. После каждого сэмпла пользователя просят оценить качество ответа модели. Для запуска модели необходимо выполнить команду:
    ```
    python main.py --config_path <config_path>
    ```
    Доступные конфиги находятся в папке ./configs/evaluation
    
3) Dataset collection. Пользователь вводит запрос вручную. Общение с агентом происходит через командную строку. После каждого действия модели пользователь должен оценить его с помощью 1 или 0. В случае положительной оценки пример добавляется в датасет. Для запуска модели необходимо выполнить команду:
    ```
    python main.py --config_path <config_path>
    ```
    Доступные конфиги находятся в папке ./configs/dataset_collection


## Дообучение модели
Код для дообучения модели находится в папке ./finetuning


##  Стэк
* LangChain, Peft
* Models: Gpt_4o, Mistral7b-Instruct-v0.3
* Experiments tracking: Wandb
* Dataset Storage: Yandex CLoud S3
* Code formatters: ruff, isort


## Структура проекта
```
.
├── configs                              # Configuration files for model inference, evaluation and dataset collection
│   ├── dataset_collection               # Contains configuration for dataset collection
│   ├── evaluation                       # Contains configuration for evaluation
│   └── inference                        # Contains configuration for inference 
├── data                                 # All project data
│   ├── airplane_schedule.csv            # Dataset with airplane schedule, file downloads from S3 with the first run of main.py
│   ├── eval_dataset.csv                 # Dataset for evaluation
│   ├── notebooks                        # Folder with notebooks connected with data
│   │   └── dataset_creation.ipynb       # This notebook was used to generate airplane schedule dataset
│   └── train_dataset.csv                # Dataset for training model
├── experiments                          # Folder with evaluation results
├── finetuning                           # Folder with script for finetuning
├── main.py                              # Service entrypoint 
├── src                                  # Folder with service code
├── utils                                # Utility
├── README.md                            # The top-level README for developers using this project.

```

## Лицензия

MIT License